{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11120729-4909-4f9f-939f-6099b6f3465b",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6536ea8-4bb8-4d84-98fb-9a3ef5886275",
   "metadata": {},
   "source": [
    "Web scraping is the automated process of extracting information from websites. It involves writing code that simulates a human visiting a webpage, fetching the HTML content of the page, and then parsing that content to extract specific data or information. Web scraping allows to gather data from websites without having to manually visit each page and copy-paste the information, making it a powerful tool for collecting, analyzing, and utilizing large amounts of data from the internet.\n",
    "\n",
    "Web scraping is used for various purposes such as data collection and analysis, competitor monitoring, content aggregation, real estate, financial data extraction, job market analysis, social media, weather etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0d7bb-728d-4ddc-a10c-e26cb0bf1433",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fd926-ec23-435f-8967-6146ef804f17",
   "metadata": {},
   "source": [
    "Web scraping can be done using a variety of methods and tools, each with its own advantages and limitations. Here are some common methods used for web scraping:\n",
    "\n",
    "Manual Copy-Pasting: This basic method involves manually copying and pasting data from a webpage into a local document or spreadsheet. It's suitable for small-scale data extraction but is time-consuming and not practical for larger tasks.\n",
    "\n",
    "Regular Expressions (Regex): Regular expressions are used to search and extract specific patterns of text from HTML content. While powerful, regex can be complex to write and maintain, especially when dealing with complex HTML structures.\n",
    "\n",
    "HTTP Libraries: Programming languages like Python offer libraries (e.g., Requests, urllib) to make HTTP requests and retrieve HTML content from websites. Once the content is fetched, parsing libraries are used to extract data.\n",
    "\n",
    "HTML Parsing Libraries: Libraries like Beautiful Soup (Python) and Cheerio (JavaScript) are commonly used to parse HTML content. They provide methods to navigate the HTML tree structure and extract specific elements and attributes.\n",
    "\n",
    "Scraping Frameworks: These frameworks combine various tools to simplify the web scraping process. Scrapy (Python) is a popular framework that handles requests, content extraction, and data storage efficiently.\n",
    "\n",
    "Headless Browsers: Headless browsers like Puppeteer (JavaScript) and Selenium (multiple languages) simulate human browsing behavior and allow interaction with dynamic content. They can be used to scrape websites that heavily rely on JavaScript for rendering.\n",
    "\n",
    "APIs: Some websites offer APIs that provide structured and machine-readable data. Using APIs is often the preferred method as it's more reliable, efficient, and legal compared to traditional scraping. However, not all websites provide APIs.\n",
    "\n",
    "Web Scraping Tools: There are various web scraping tools and platforms available that allow non-programmers to scrape websites using a visual interface. These tools often generate code in the background for the desired scraping tasks.\n",
    "\n",
    "Browser Extensions: Some browser extensions, like \"Web Scraper\" for Google Chrome, offer simple ways to scrape data from websites without extensive programming knowledge.\n",
    "\n",
    "Crawling vs. Scraping: Crawling involves systematically navigating through a website's pages to gather links and content. While scraping focuses on extracting specific data from individual pages, crawling is more about building an index of a site's content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40d631-8ba0-45eb-adf4-b85f54aee050",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f489924-67b2-4ecf-b008-1207e78bde52",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that is widely used for web scraping and parsing HTML and XML documents. It provides tools for extracting data from HTML content and navigating the document's tree structure. Beautiful Soup makes it easier to work with complex HTML documents, allowing you to extract specific elements, attributes, and text from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04541896-3344-4e0a-a6d8-935e4bb940b9",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e2d9-4997-4157-adcd-bacb6c8b0271",
   "metadata": {},
   "source": [
    "Flask itself is not directly related to web scraping but it is used in this web scraping project to create a user interface, manage routes, and display the scraped data to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465735a4-e66a-4315-8dc0-cb048931c892",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb84316a-5860-492a-a575-08784c891be3",
   "metadata": {},
   "source": [
    "The AWS services used in this project are AWS ElasticBeanstalk and AWS CodePipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
